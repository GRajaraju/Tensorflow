{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.examples.tutorials.mnist import input_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/data/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/data/t10k-images-idx3-ubyte.gz\n",
      "Extracting /tmp/data/t10k-labels-idx1-ubyte.gz\n"
     ]
    }
   ],
   "source": [
    "mnist = input_data.read_data_sets(\"/tmp/data\",one_hot=True) \n",
    "# Each image is stored as 1-dimensional array which can be accessed using mnist.train.image[index]\n",
    "# Similarly the labels can be accessed using mnist.train.labels[index]\n",
    "# enabling one_hot creates one hot encoding for each label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAP8AAAD8CAYAAAC4nHJkAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nUIQfCIrwA0ERfiCo/wEHUV9Qdt6/1wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x12fcb0e80>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(np.reshape(mnist.train.images[0],[28,28]),cmap='gray') # accessing the first image from training data\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 1., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mnist.train.labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "learning_rate = 0.01\n",
    "epochs = 500\n",
    "batch_size = 128\n",
    "n_hidden_1 = 10\n",
    "n_hidden_2 = 10\n",
    "num_input = 784\n",
    "num_classes = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tf graph input\n",
    "X = tf.placeholder(tf.float32,[None,num_input])\n",
    "Y = tf.placeholder(tf.float32,[None,num_classes])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating dictionary to store weights and biases\n",
    "weights = {\n",
    "    'h1':tf.Variable(tf.random_normal([num_input,n_hidden1])),\n",
    "    'h2':tf.Variable(tf.random_normal([n_hidden1,n_hidden2])),\n",
    "    'out':tf.Variable(tf.random_normal([n_hidden2,num_classes])),\n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1':tf.Variable(tf.random_normal([n_hidden1])),\n",
    "    'b2':tf.Variable(tf.random_normal([n_hidden2])),\n",
    "    'out':tf.Variable(tf.random_normal([num_classes])),\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating the model\n",
    "def neural_net(x):\n",
    "    layer_1 = tf.add(tf.matmul(x,weights['h1']),biases['b1'])\n",
    "    layer_2 = tf.add(tf.matmul(layer_1,weights['h2']),biases['b2'])\n",
    "    out_layer = tf.matmul(layer_2,weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "logits = neural_net(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining loss and model optimizer\n",
    "loss_op = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits_v2(logits=logits,labels=Y))\n",
    "optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "train_op = optimizer.minimize(loss_op)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluating model performance\n",
    "correct_pred = tf.equal(tf.argmax(logits,1),tf.argmax(Y,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_pred,tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing the global variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch1,Minibatch loss=1594.0144,Training Accuracy=0.164\n",
      "Optimization finished\n",
      "Testing Accuracy: 0.1469\n",
      "epoch100,Minibatch loss=180.9144,Training Accuracy=0.844\n",
      "Optimization finished\n",
      "Testing Accuracy: 0.8812\n",
      "epoch200,Minibatch loss=61.6442,Training Accuracy=0.883\n",
      "Optimization finished\n",
      "Testing Accuracy: 0.8756\n",
      "epoch300,Minibatch loss=86.9222,Training Accuracy=0.859\n",
      "Optimization finished\n",
      "Testing Accuracy: 0.8893\n",
      "epoch400,Minibatch loss=71.8191,Training Accuracy=0.875\n",
      "Optimization finished\n",
      "Testing Accuracy: 0.8704\n",
      "epoch500,Minibatch loss=63.3633,Training Accuracy=0.852\n",
      "Optimization finished\n",
      "Testing Accuracy: 0.8888\n"
     ]
    }
   ],
   "source": [
    "# start training\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    for epoch in range(1,epochs+1):\n",
    "        batch_x,batch_y = mnist.train.next_batch(batch_size)\n",
    "        sess.run(train_op,feed_dict={X:batch_x,Y:batch_y})\n",
    "        if epoch % 100 == 0 or epoch == 1:\n",
    "            loss,acc = sess.run([loss_op,accuracy],feed_dict={X:batch_x,Y:batch_y})\n",
    "            print(\"epoch\" + str(epoch) + \",Minibatch loss=\" + \"{:.4f}\".format(loss) + \",Training Accuracy=\"+\"{:.3f}\".format(acc))\n",
    "            print(\"Optimization finished\")\n",
    "            print(\"Testing Accuracy:\",sess.run(accuracy,feed_dict={X:mnist.test.images,Y:mnist.test.labels}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
